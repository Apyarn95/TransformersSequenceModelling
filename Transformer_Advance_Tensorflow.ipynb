{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_Advance_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNH703zh4OV+ddLJueC1+NS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apyarn95/TransformersSequenceModelling/blob/master/Transformer_Advance_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq3p0GW3J_wB"
      },
      "source": [
        "#this is an advancement on basic transformer architecture . This architecture makes maximum use of the multiprocessing power of gpu and\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time\n",
        "import pandas as pd \n",
        "#this is to inform you are a piece of hsit"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "483vsCgoK2w9",
        "outputId": "a5403a5b-2a82-4b17-b4d1-bab0f949bdd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/My Drive/eng_french.csv',nrows=80000)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vt8h9arsdcq",
        "outputId": "9d123856-9ea5-47fa-fea8-2d98c74b6130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "      <th>len_english</th>\n",
              "      <th>len_french</th>\n",
              "      <th>data_english</th>\n",
              "      <th>data_french_input</th>\n",
              "      <th>data_french_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7714</th>\n",
              "      <td>I am a shy boy.</td>\n",
              "      <td>Je suis un garçon timide.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>i am a shy boy .</td>\n",
              "      <td>&lt;sostoken&gt; je suis un garcon timide .</td>\n",
              "      <td>je suis un garcon timide . &lt;eostoken&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7720</th>\n",
              "      <td>I am in a spot.</td>\n",
              "      <td>Je suis dans le pétrin.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>i am in a spot .</td>\n",
              "      <td>&lt;sostoken&gt; je suis dans le petrin .</td>\n",
              "      <td>je suis dans le petrin . &lt;eostoken&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7721</th>\n",
              "      <td>I am in a spot.</td>\n",
              "      <td>Je suis dans un endroit.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>i am in a spot .</td>\n",
              "      <td>&lt;sostoken&gt; je suis dans un endroit .</td>\n",
              "      <td>je suis dans un endroit . &lt;eostoken&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7883</th>\n",
              "      <td>I had to do it.</td>\n",
              "      <td>Il m'a fallu le faire.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>i had to do it .</td>\n",
              "      <td>&lt;sostoken&gt; il m a fallu le faire .</td>\n",
              "      <td>il m a fallu le faire . &lt;eostoken&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8135</th>\n",
              "      <td>I saw it on TV.</td>\n",
              "      <td>Je l'ai vu à la télé.</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>i saw it on tv .</td>\n",
              "      <td>&lt;sostoken&gt; je l ai vu a la tele .</td>\n",
              "      <td>je l ai vu a la tele . &lt;eostoken&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     English words/sentences  ...                     data_french_output\n",
              "7714         I am a shy boy.  ...  je suis un garcon timide . <eostoken>\n",
              "7720         I am in a spot.  ...    je suis dans le petrin . <eostoken>\n",
              "7721         I am in a spot.  ...   je suis dans un endroit . <eostoken>\n",
              "7883         I had to do it.  ...     il m a fallu le faire . <eostoken>\n",
              "8135         I saw it on TV.  ...      je l ai vu a la tele . <eostoken>\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRGQd2y6u1J"
      },
      "source": [
        "data['len_english'] = data['English words/sentences'].apply(lambda x : len(x.split(\" \")))\n",
        "data['len_french'] = data['French words/sentences'].apply(lambda x : len(x.split(\" \")))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLNwT0Cy7Pgs"
      },
      "source": [
        "data = data[data['len_english'] >= 5]\n",
        "data = data[data['len_french'] >= 5]\n",
        "data = data[data['len_english'] <= 14]\n",
        "data = data[data['len_french'] <= 14]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WnsApuwK4uS"
      },
      "source": [
        "#preprocessing\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',s) \n",
        "                  if unicodedata.category(c)!= 'Mn')\n",
        "\n",
        "def preprocess(s):\n",
        "  s = s.lower()\n",
        "  s = unicode_to_ascii(s)\n",
        "  s = re.sub(r'([!.?])', r' \\1', s)\n",
        "  #creating space between word and punctuation following\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "  s = re.sub(r'\\s+', r' ', s)\n",
        "  return s\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrRB18Rygvdv"
      },
      "source": [
        "data['data_english'] = data['English words/sentences'].apply(lambda x:preprocess(x))\n",
        "data['data_french_input'] = data['French words/sentences'].apply(lambda x : ('<sostoken> ' + preprocess(x)).strip())\n",
        "data['data_french_output'] = data['French words/sentences'].apply(lambda x :  (preprocess(x).strip() + ' <eostoken>'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH_QIHbtK9i4"
      },
      "source": [
        "# data_english , data_french = list(zip(*data))\n",
        "# data_english , data_french = list(data_english) , list(data_french)\n",
        "# data_english = [preprocess(data) for data in data_english]\n",
        "# data_french_input = ['<sostoken> ' + preprocess(data) for data in data_french]\n",
        "# data_french_output = [preprocess(data)+' <eostoken>' for data in data_french]\n",
        "data_english = data['data_english'].tolist()\n",
        "data_french_input = data['data_french_input'].tolist()\n",
        "data_french_output = data['data_french_output'].tolist()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "842ZRotoLLWU"
      },
      "source": [
        "# Tokenization of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu5P3v6TK_TN"
      },
      "source": [
        "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "en_tokenizer.fit_on_texts(data_english)\n",
        "data_en = en_tokenizer.texts_to_sequences(data_english)\n",
        "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en,\n",
        "                                                        padding='post')\n",
        "\n",
        "fr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "fr_tokenizer.fit_on_texts(data_french_input)\n",
        "fr_tokenizer.fit_on_texts(data_french_output)\n",
        "data_fr_in = fr_tokenizer.texts_to_sequences(data_french_input)\n",
        "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in,\n",
        "                                                           padding='post')\n",
        "\n",
        "data_fr_out = fr_tokenizer.texts_to_sequences(data_french_output)\n",
        "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out,\n",
        "                                                            padding='post')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6zWn3j8h1ar",
        "outputId": "4ffb3ae1-18b4-4f68-f4db-b47551258cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NORRKeQNLtwv"
      },
      "source": [
        "# Creating tensorflow data object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tfY0lY_LrUY"
      },
      "source": [
        "BATCH_SIZE_ = 128\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data_en,data_fr_in,data_fr_out))\n",
        "dataset = dataset.shuffle(20).batch(BATCH_SIZE_)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRatNk08jUKN",
        "outputId": "beafb099-1f20-4605-a8fd-ff5a750082d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 7), (None, 11), (None, 11)), types: (tf.int32, tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJHw_WtAL2j-"
      },
      "source": [
        "# Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m0TJ7L9LPwh"
      },
      "source": [
        "def positional_embedding(pos, model_size):\n",
        "    PE = np.zeros((1, model_size))\n",
        "    for i in range(model_size):\n",
        "        if i % 2 == 0:\n",
        "            PE[:, i] = np.sin(pos / 10000 ** (i / model_size))\n",
        "        else:\n",
        "            PE[:, i] = np.cos(pos / 10000 ** ((i - 1) / model_size))\n",
        "    return PE\n",
        "\n",
        "max_length = max(len(data_en[0]), len(data_fr_in[0]))\n",
        "MODEL_SIZE = 300\n",
        "\n",
        "pes = []\n",
        "for i in range(max_length):\n",
        "    pes.append(positional_embedding(i, MODEL_SIZE))\n",
        "\n",
        "pes = np.concatenate(pes, axis=0)\n",
        "pes = tf.constant(pes, dtype=tf.float32)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ75O0-2MAL6"
      },
      "source": [
        "# Mulithead attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZblOSvbL9_O"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.Model):\n",
        "    def __init__(self, model_size, h):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.key_size = model_size // h\n",
        "        self.h = h\n",
        "        self.wq = tf.keras.layers.Dense(model_size) #[tf.keras.layers.Dense(key_size) for _ in range(h)]\n",
        "        self.wk = tf.keras.layers.Dense(model_size) #[tf.keras.layers.Dense(key_size) for _ in range(h)]\n",
        "        self.wv = tf.keras.layers.Dense(model_size) #[tf.keras.layers.Dense(value_size) for _ in range(h)]\n",
        "        self.wo = tf.keras.layers.Dense(model_size)\n",
        "    \n",
        "    def call(self, decoder_output, encoder_output, mask=None):\n",
        "        \n",
        "        \n",
        "        query = self.wq(decoder_output)\n",
        "        key = self.wk(encoder_output)\n",
        "        value = self.wv(encoder_output)\n",
        "        \n",
        "        # Split for multihead attention\n",
        "        batch_size = query.shape[0]\n",
        "        query = tf.reshape(query, [batch_size, -1, self.h, self.key_size])\n",
        "        query = tf.transpose(query, [0, 2, 1, 3])\n",
        "        key = tf.reshape(key, [batch_size, -1, self.h, self.key_size])\n",
        "        key = tf.transpose(key, [0, 2, 1, 3])\n",
        "        value = tf.reshape(value, [batch_size, -1, self.h, self.key_size])\n",
        "        value = tf.transpose(value, [0, 2, 1, 3])\n",
        "        \n",
        "        score = tf.matmul(query, key, transpose_b=True) / tf.math.sqrt(tf.dtypes.cast(self.key_size, dtype=tf.float32))\n",
        "        \n",
        "        if mask is not None:\n",
        "            score *= mask\n",
        "            score = tf.where(tf.equal(score, 0), tf.ones_like(score) * -1e9, score)\n",
        "        \n",
        "        alignment = tf.nn.softmax(score, axis=-1)\n",
        "        context = tf.matmul(alignment, value)\n",
        "        context = tf.transpose(context, [0, 2, 1, 3])\n",
        "        context = tf.reshape(context, [batch_size, -1, self.key_size * self.h])\n",
        "        \n",
        "        heads = self.wo(context)\n",
        "        # heads has shape (batch, decoder_len, model_size)\n",
        "        return heads"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNu5wVMTMGoC"
      },
      "source": [
        "# Encoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbMx0_mfMMSx"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, model_size, num_layers, h):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model_size = model_size\n",
        "        self.num_layers = num_layers\n",
        "        self.h = h\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, model_size)\n",
        "        self.attention = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
        "\n",
        "        self.attention_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "\n",
        "        self.dense_1 = [tf.keras.layers.Dense(512, activation='relu') for _ in range(num_layers)]\n",
        "        self.dense_2 = [tf.keras.layers.Dense(model_size) for _ in range(num_layers)]\n",
        "        self.ffn_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, sequence, padding_mask=None):\n",
        "        embed_out = self.embedding(sequence)\n",
        "        embed_out += pes[:sequence.shape[1], :]\n",
        "        \n",
        "        sub_in = embed_out\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            sub_out = self.attention[i](sub_in, sub_in, padding_mask)\n",
        "            sub_out = sub_in + sub_out\n",
        "            sub_out = self.attention_norm[i](sub_out)\n",
        "            \n",
        "            ffn_in = sub_out\n",
        "\n",
        "            ffn_out = self.dense_2[i](self.dense_1[i](ffn_in))\n",
        "            ffn_out = ffn_in + ffn_out\n",
        "            ffn_out = self.ffn_norm[i](ffn_out)\n",
        "\n",
        "            sub_in = ffn_out\n",
        "            \n",
        "        return ffn_out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqfsex7HMbRe"
      },
      "source": [
        "# Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmGrVX5MMfUF"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, model_size, num_layers, h):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.model_size = model_size\n",
        "        self.num_layers = num_layers\n",
        "        self.h = h\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, model_size)\n",
        "        self.attention_bot = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
        "        self.attention_bot_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "        self.attention_mid = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
        "        self.attention_mid_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "        \n",
        "        self.dense_1 = [tf.keras.layers.Dense(512, activation='relu') for _ in range(num_layers)]\n",
        "        self.dense_2 = [tf.keras.layers.Dense(model_size) for _ in range(num_layers)]\n",
        "        self.ffn_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "        \n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, sequence, encoder_output, padding_mask=None):\n",
        "        # EMBEDDING AND POSITIONAL EMBEDDING\n",
        "        embed_out = self.embedding(sequence)\n",
        "        embed_out += pes[:sequence.shape[1], :]\n",
        "        \n",
        "        bot_sub_in = embed_out\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            # BOTTOM MULTIHEAD SUB LAYER\n",
        "            seq_len = bot_sub_in.shape[1]\n",
        "            look_left_only_mask = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "            bot_sub_out = self.attention_bot[i](bot_sub_in, bot_sub_in, look_left_only_mask)\n",
        "            bot_sub_out = bot_sub_in + bot_sub_out\n",
        "            bot_sub_out = self.attention_bot_norm[i](bot_sub_out)\n",
        "            \n",
        "            # MIDDLE MULTIHEAD SUB LAYER\n",
        "            mid_sub_in = bot_sub_out\n",
        "\n",
        "            mid_sub_out = self.attention_mid[i](mid_sub_in, encoder_output, padding_mask)\n",
        "            mid_sub_out = mid_sub_out + mid_sub_in\n",
        "            mid_sub_out = self.attention_mid_norm[i](mid_sub_out)\n",
        "\n",
        "            # FFN\n",
        "            ffn_in = mid_sub_out\n",
        "\n",
        "            ffn_out = self.dense_2[i](self.dense_1[i](ffn_in))\n",
        "            ffn_out = ffn_out + ffn_in\n",
        "            ffn_out = self.ffn_norm[i](ffn_out)\n",
        "\n",
        "            bot_sub_in = ffn_out\n",
        "        \n",
        "        logits = self.dense(ffn_out)\n",
        "            \n",
        "        return logits"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAg2QgNWMsT1"
      },
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True)\n",
        "def loss_func(targets, logits):\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTToco_gMvF1"
      },
      "source": [
        "def predict(test_source_text=None):\n",
        "    if test_source_text is None:\n",
        "        test_source_text = data_english[np.random.choice(len(data_english))]\n",
        "    print(test_source_text)\n",
        "    test_source_seq = en_tokenizer.texts_to_sequences([test_source_text])\n",
        "    print(test_source_seq)\n",
        "\n",
        "    en_output = encoder(tf.constant(test_source_seq))\n",
        "\n",
        "    de_input = tf.constant([[fr_tokenizer.word_index['<sostoken>']]], dtype=tf.int64)\n",
        "\n",
        "    out_words = []\n",
        "\n",
        "    while True:\n",
        "        de_output = decoder(de_input, en_output)\n",
        "        new_word = tf.expand_dims(tf.argmax(de_output, -1)[:, -1], axis=1)\n",
        "        out_words.append(fr_tokenizer.index_word[new_word.numpy()[0][0]])\n",
        "\n",
        "        de_input = tf.concat((de_input, new_word), axis=-1)\n",
        "\n",
        "        if out_words[-1] == '<eostoken>' or len(out_words) >= 10:\n",
        "            break\n",
        "\n",
        "    print(' '.join(out_words))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DsFCv3HMwg3"
      },
      "source": [
        "@tf.function\n",
        "def train_step(source_seq, target_seq_in, target_seq_out):\n",
        "    with tf.GradientTape() as tape:\n",
        "        padding_mask = 1 - tf.cast(tf.equal(source_seq, 0), dtype=tf.float32)\n",
        "        padding_mask = tf.expand_dims(padding_mask, axis=1)\n",
        "        padding_mask = tf.expand_dims(padding_mask, axis=1)\n",
        "        encoder_output = encoder(source_seq, padding_mask)\n",
        "        \n",
        "        decoder_output = decoder(target_seq_in, encoder_output, padding_mask)\n",
        "\n",
        "        loss = loss_func(target_seq_out, decoder_output)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6FwsTU1Mx9f",
        "outputId": "33eefcb6-7d51-4806-9cb3-7a88e46c2d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NUM_LAYERS = 4\n",
        "H = 4\n",
        "in_vocab_size = len(en_tokenizer.word_index)+1\n",
        "out_vocab_size = len(fr_tokenizer.word_index)+1\n",
        "encoder = Encoder(in_vocab_size, MODEL_SIZE, NUM_LAYERS, H)\n",
        "decoder = Decoder(out_vocab_size, MODEL_SIZE, NUM_LAYERS, H)\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "start_time = time.time()\n",
        "for e in range(NUM_EPOCHS):\n",
        "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "        loss = train_step(source_seq, target_seq_in,target_seq_out)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(\n",
        "          e + 1, loss.numpy()))\n",
        "\n",
        "    if (e + 1) % 10 == 0:\n",
        "        end_time = time.time()\n",
        "        print('Average elapsed time: {:.2f}s'.format((end_time - start_time) / (e + 1)))\n",
        "        try:\n",
        "            predict()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 2.6879\n",
            "Epoch 2 Loss 2.3960\n",
            "Epoch 3 Loss 2.9521\n",
            "Epoch 4 Loss 3.4382\n",
            "Epoch 5 Loss 2.6638\n",
            "Epoch 6 Loss 1.8867\n",
            "Epoch 7 Loss 3.2869\n",
            "Epoch 8 Loss 1.8722\n",
            "Epoch 9 Loss 1.7625\n",
            "Epoch 10 Loss 1.5821\n",
            "Average elapsed time: 15.64s\n",
            "tom was shot in the leg . \n",
            "[[10, 28, 493, 26, 8, 609, 1]]\n",
            "tom etait dans tom tom tom . <eostoken>\n",
            "Epoch 11 Loss 1.2029\n",
            "Epoch 12 Loss 2.1495\n",
            "Epoch 13 Loss 1.7730\n",
            "Epoch 14 Loss 2.5962\n",
            "Epoch 15 Loss 1.0851\n",
            "Epoch 16 Loss 1.0686\n",
            "Epoch 17 Loss 0.4954\n",
            "Epoch 18 Loss 1.5528\n",
            "Epoch 19 Loss 0.3746\n",
            "Epoch 20 Loss 0.6439\n",
            "Average elapsed time: 15.09s\n",
            "when will we go home ? \n",
            "[[150, 82, 18, 37, 80, 5]]\n",
            "quand allons nous nous rendre ? <eostoken>\n",
            "Epoch 21 Loss 1.1378\n",
            "Epoch 22 Loss 1.0409\n",
            "Epoch 23 Loss 0.4193\n",
            "Epoch 24 Loss 0.5797\n",
            "Epoch 25 Loss 2.1686\n",
            "Epoch 26 Loss 0.2490\n",
            "Epoch 27 Loss 1.0539\n",
            "Epoch 28 Loss 0.3042\n",
            "Epoch 29 Loss 0.5682\n",
            "Epoch 30 Loss 0.0222\n",
            "Average elapsed time: 14.89s\n",
            "i can t tell what it is . \n",
            "[[2, 17, 7, 79, 25, 11, 9, 1]]\n",
            "je ne peux pas savoir quoi c est ce que\n",
            "Epoch 31 Loss 0.4675\n",
            "Epoch 32 Loss 0.4273\n",
            "Epoch 33 Loss 0.6305\n",
            "Epoch 34 Loss 0.9641\n",
            "Epoch 35 Loss 0.2752\n",
            "Epoch 36 Loss 0.8061\n",
            "Epoch 37 Loss 0.2609\n",
            "Epoch 38 Loss 0.0124\n",
            "Epoch 39 Loss 0.0114\n",
            "Epoch 40 Loss 0.0019\n",
            "Average elapsed time: 14.79s\n",
            "do you come here often ? \n",
            "[[12, 3, 87, 46, 277, 5]]\n",
            "tu viens souvent ici ? <eostoken>\n",
            "Epoch 41 Loss 0.3721\n",
            "Epoch 42 Loss 0.0443\n",
            "Epoch 43 Loss 0.4479\n",
            "Epoch 44 Loss 0.0862\n",
            "Epoch 45 Loss 0.1032\n",
            "Epoch 46 Loss 0.1030\n",
            "Epoch 47 Loss 0.0618\n",
            "Epoch 48 Loss 0.3494\n",
            "Epoch 49 Loss 0.1037\n",
            "Epoch 50 Loss 0.0740\n",
            "Average elapsed time: 14.74s\n",
            "pizza is my favorite food . \n",
            "[[920, 9, 22, 1101, 384, 1]]\n",
            "la pizza est mon plat prefere . <eostoken>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDmTRNKx4AQv",
        "outputId": "475738c8-60e8-46a1-b82b-27e48bf6caa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "test_data =['I am a shy boy','I had to do it']\n",
        "for t in test_data:\n",
        "  pro = preprocess(t)\n",
        "  predict(pro)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i am a shy boy\n",
            "[[2, 88, 6, 855, 241]]\n",
            "je suis un garcon timide . <eostoken>\n",
            "i had to do it\n",
            "[[2, 59, 4, 12, 11]]\n",
            "il m a fallu le faire . <eostoken>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}